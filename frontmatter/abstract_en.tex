\chapter*{Abstract}
\addcontentsline{toc}{chapter}{Abstract}
\markboth{\uppercase{Abstract}}{\uppercase{Abstract}}

Human identification, which aims at finding a target person of interest from a gallery of digital photos, is one of the fundamental problems in computer vision. It is a key component in many real-world applications including smart phone apps, self-driving cars, home security systems, and intelligent surveillance cameras.

Thanks to the development of deep learning research and large-scale well annotated datasets, deep neural networks are now capable of recognizing thousands of object categories. However, human identification is still challenging because it lacks a dataset large enough to supervise the model training. Moreover, existing small datasets usually have their own image biases, which makes it hard to learn a single model that generalizes over all these domains. Meanwhile, most of the existing research simplified the problem setting, which leaves a gap between research approaches and practical applications.

In this dissertation we address these challenges from three aspects to make human identification scalable to real-world data and applications. First, we propose a semi-supervised deep learning framework that uses noisy-labeled rather than well annotated data. We collect a large-scale clothing dataset with noisy annotations, from which we can learn good representations for clothes that help recognize human. Second, we develop a joint single task learning algorithm and a domain guided dropout technique to learn a single model from multiple human identification datasets with domain biases. It enables us to collectively use the data contributed by different people in the community. At last, we focus on the more realistic problem setting that finds a target person in whole scene images. We develop a unified framework that combines person detection and identification, as well as a loss function that trains the identification model effectively.